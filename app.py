# -*- coding: utf-8 -*-
"""ia_me_app_03062025_1812.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_dEz_dkFC6fA_Ybg0HoEmGdDFBTJYXAv
"""

# Import des librairies
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import re
import nltk
import string
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from textblob import TextBlob

# T√©l√©charger stopwords et autres ressources NLTK si besoin
nltk.download('stopwords')
nltk.download('punkt')

# Chargement des donn√©es (ici on suppose que le fichier csv est upload√© dans Colab)
df = pd.read_csv('ia-me/suivi_activites.csv', sep=',', encoding='utf-8', quotechar='"')

# Apercu
print(df.columns)
print(df.head())
print(df.info())

# Conversion des donn√©es de la colonne Date en type date
df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d', errors='coerce')

# Traitement des valeurs manquantes (voir nombre)
print(df.isnull().sum())

# V√©rification des doublons
print(df.duplicated().sum())

# Nettoyage basique du texte (feedback)
def clean_text(text):
    if pd.isnull(text):
        return ""
    # Mise en minuscule
    text = text.lower()
    # Suppression ponctuation
    text = text.translate(str.maketrans('', '', string.punctuation))
    # Suppression chiffres
    text = re.sub(r'\d+', '', text)
    # D√©finir les stopwords en fran√ßais ou anglais selon votre jeu de donn√©es
    stop_words = set(stopwords.words('french'))
    # Suppression des stopwords
    text = ' '.join([mot for mot in text.split() if mot not in stop_words])
    return text

df['feedback_clean'] = df['feedback'].apply(clean_text)

# V√©rification si le traitement s'est bien d√©roul√© et que la colonne trait√©e n'est pas vide
print(df['feedback_clean'].head())

"""√Ä ce stade :
*   La colonne Date est bien format√©e
*   Les doublons sont supprim√©s
*   √âl√©ment de liste
*   Les Feedback sont nettoy√©s et une nouvelle colonne Feedback_clean est cr√©√©e
*   Les champs manquants sont visibles pour traitement ult√©rieur√âl√©ment de liste


"""

# ANALYSE EXPLORATOIRE DE BASE (EDA)

# Aper√ßu des statistiques descriptives des colonnes num√©riques
print("R√©sum√© statistique des colonnes num√©riques :")
print(df.describe())  # Affiche count, mean, std, min, 25%, 50%, 75%, max pour les colonnes num√©riques

# Nombre de valeurs uniques par colonne
print("\nNombre de valeurs uniques par colonne :")
print(df.nunique())  # Permet d'identifier les variables cat√©gorielles ou constantes

# Aper√ßu rapide des types de donn√©es
print("\nTypes de donn√©es dans le DataFrame :")
print(df.dtypes)  # V√©rifie les types (object, int64, float64, etc.)

# V√©rification de la pr√©sence de valeurs manquantes
print("\nNombre de valeurs manquantes par colonne :")
print(df.isnull().sum())  # Pour d√©tecter les colonnes incompl√®tes ou probl√©matiques

# Check if there are any non-empty strings after cleaning and stopword removal
if df['feedback_clean'].str.strip().eq('').all():
    print("Erreur: Apr√®s nettoyage et suppression des mots vides, la colonne 'Feedback_clean' est vide. Impossible de cr√©er un vocabulaire TF-IDF.")
    # Option 1: Print some raw feedback to understand why it's empty
    print("\nExemples de feedback originaux :")
    print(df['feedback'].head())
    # Option 2: You might need to revisit your cleaning steps or data source
else:
    vectorizer = TfidfVectorizer(max_features=20)
    X = vectorizer.fit_transform(df['feedback_clean'])
    tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())

    # Somme des TF-IDF par mot pour voir les plus importants
    tfidf_sum = tfidf_df.sum().sort_values(ascending=False)
    print("Top mots-cl√©s TF-IDF :")
    print(tfidf_sum)

X = vectorizer.fit_transform(df['feedback_clean'])
tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())

# Somme des TF-IDF par mot pour voir les plus importants
tfidf_sum = tfidf_df.sum().sort_values(ascending=False)
print("Top mots-cl√©s TF-IDF :")
print(tfidf_sum)

# Analyse de sentiment avec TextBlob (en fran√ßais)
# On utilise TextBlob directement ici, qui marche mieux en anglais, mais √ßa donnera un aper√ßu
# Pour un vrai traitement en fran√ßais, on pourrait utiliser d‚Äôautres libs (ex: HuggingFace)
def sentiment_polarity(text):
    return TextBlob(text).sentiment.polarity

df['sentiment'] = df['feedback_clean'].apply(sentiment_polarity)

# Cat√©gorisation simple du sentiment
def categorize_sentiment(score):
    if score > 0.1:
        return 'Positif'
    elif score < -0.1:
        return 'N√©gatif'
    else:
        return 'Neutre'

df['sentiment_cat'] = df['sentiment'].apply(categorize_sentiment)

# Affichage des counts sentiment
print("\nR√©partition des sentiments :")
print(df['sentiment_cat'].value_counts())

# Nuage de mots pour feedback global
all_text = ' '.join(df['feedback_clean'])
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)

plt.figure(figsize=(12,6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title("Nuage de mots - Feedback\n \n")
plt.show()

# Graphique des sentiments par type d'activit√©
plt.figure(figsize=(10,6))
sns.countplot(data=df, x='type_activite', hue='sentiment_cat')
plt.title("Sentiments par Type d'Activit√© \n")
plt.xticks(rotation=45)
plt.show()

# Moyenne de sentiment par localisation
sentiment_localisation = df.groupby('localisation')['sentiment'].mean().sort_values()

plt.figure(figsize=(8,5))
sentiment_localisation.plot(kind='bar', color='skyblue')
plt.title("Moyenne du sentiment par localisation \n")
plt.ylabel("Score moyen de sentiment \n")
plt.show()

# Croisement nombre participants vs sentiment (boxplot)
plt.figure(figsize=(8,5))
sns.boxplot(data=df, x='sentiment_cat', y='nombre_participants')
plt.title("Nombre de participants selon sentiment \n")
plt.show()

from transformers import pipeline
from tqdm import tqdm

# Nettoyage des feedbacks
df = df.dropna(subset=['feedback'])  # Retirer les lignes sans feedback
feedbacks = df['feedback'].astype(str).tolist()
# Pipeline de sentiment en fran√ßais
sentiment_model = pipeline("sentiment-analysis", model="tblard/tf-allocine")

# Appliquer le mod√®le aux feedbacks (limit√© ici √† 100 pour √©viter les quotas)
df['sentiment'] = df['feedback'].apply(lambda x: sentiment_model(x[:512])[0]['label'])

# Traitement par batchs
batch_size = 2
sentiments = []

for i in tqdm(range(0, len(feedbacks), batch_size)):
    batch = feedbacks[i:i+batch_size]
    # Tronquer les textes trop longs (optionnel)
    batch = [text[:512] for text in batch]
    results = sentiment_model(batch)
    sentiments.extend([res['label'] for res in results])

# Ajouter la colonne au DataFrame
df = df.reset_index(drop=True)
df['sentiment'] = sentiments

# Affichage des r√©sultats
print(df[['feedback', 'sentiment']].head(10))

### Analyse temporelle des sentiments

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression

# S'assurer que la date est bien en datetime
df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d', errors='coerce')

# Nettoyage des labels sentiments (juste au cas o√π)
#df['sentiment'] = df['sentiment'].astype(str).str.upper().str.strip()
# Convertir en float si ce n‚Äôest pas d√©j√† fait
df['sentiment'] = df['sentiment'].astype(float)

# Cr√©er une nouvelle colonne avec labels
def classer_sentiment(score):
    if score > 0.1:
        return 'POS'
    elif score < -0.1:
        return 'NEG'
    else:
        return 'NEU'  # si tu veux ignorer les neutres, tu peux les exclure ensuite

df['sentiment_label'] = df['sentiment'].apply(classer_sentiment)

# Cr√©er une copie filtr√©e pour analyse
df_filtered = df[df['sentiment_label'].isin(['POS', 'NEG'])].copy()

# Cr√©er colonne mois-ann√©e
df_filtered['mois_annee'] = df_filtered['date'].dt.to_period('M').astype(str)

# Agr√©gation des feedbacks par mois et sentiment
sentiment_par_mois = df_filtered.groupby(['mois_annee', 'sentiment_label']).size().unstack(fill_value=0)

# Convertir l'index en entier pour les r√©gressions
mois_index = np.arange(len(sentiment_par_mois)).reshape(-1, 1)

sentiment_par_mois = sentiment_par_mois.astype(int)

# Tracer le graphique avec lignes de tendance
plt.figure(figsize=(12, 6))

sentiment_par_mois.plot(
    kind='bar',
    color={'POS': '#66bb6a', 'NEG': '#ef5350'},
    edgecolor='black',
    width=0.75,
    ax=plt.gca()
)

# Ajout des courbes de tendance
for sentiment in ['POS', 'NEG']:
    y = sentiment_par_mois[sentiment].values
    model = LinearRegression().fit(mois_index, y)
    trend = model.predict(mois_index)
    plt.plot(sentiment_par_mois.index, trend, linestyle='--', linewidth=2, label=f"Tendance {sentiment}")

# Finalisation
plt.title("√âvolution des sentiments par mois avec tendance \n")
plt.xlabel("Mois-Ann√©e")
plt.ylabel("Nombre de feedbacks")
plt.xticks(rotation=45)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.legend(title="L√©gende")
plt.tight_layout()
plt.show()

# === G√©n√©ration d'un commentaire automatique ===
last = sentiment_par_mois.iloc[-1]
first = sentiment_par_mois.iloc[0]

evolution_pos = last['POS'] - first['POS']
evolution_neg = last['NEG'] - first['NEG']

commentaire = "üîé **Analyse automatique :**\n"

if evolution_pos > 0:
    commentaire += f"- Les feedbacks **positifs ont augment√©** de {evolution_pos} entre {sentiment_par_mois.index[0]} et {sentiment_par_mois.index[-1]}.\n"
elif evolution_pos < 0:
    commentaire += f"- Les feedbacks **positifs ont diminu√©** de {-evolution_pos} sur la m√™me p√©riode.\n"
else:
    commentaire += "- Les feedbacks **positifs sont rest√©s stables**.\n"

if evolution_neg > 0:
    commentaire += f"- Les feedbacks **n√©gatifs ont augment√©** de {evolution_neg}.\n"
elif evolution_neg < 0:
    commentaire += f"- Les feedbacks **n√©gatifs ont diminu√©** de {-evolution_neg}.\n"
else:
    commentaire += "- Les feedbacks **n√©gatifs sont rest√©s stables**.\n"

print(commentaire)
#

### Clustering thematique des feedbacks
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.manifold import TSNE

# Vectorisation TF-IDF
vectorizer = TfidfVectorizer(max_features=1000, max_df=0.8, min_df=5)
X = vectorizer.fit_transform(df['feedback_clean'])

# Clustering avec KMeans
n_clusters = 5
kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
kmeans.fit(X)

df['cluster'] = kmeans.labels_

# Affichage des mots-cl√©s par cluster
terms = vectorizer.get_feature_names_out()
order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]

print("üßæ Mots-cl√©s principaux par cluster :\n")
for i in range(n_clusters):
    print(f"Cluster {i} :")
    print(", ".join([terms[ind] for ind in order_centroids[i, :10]]))
    print()

# Visualisation 2D avec t-SNE
tsne = TSNE(n_components=2, random_state=42)
X_embedded = tsne.fit_transform(X.toarray())

plt.figure(figsize=(10, 8))
sns.scatterplot(x=X_embedded[:, 0], y=X_embedded[:, 1], hue=df['cluster'], palette='viridis', s=50)
plt.title("Projection 2D des feedbacks par cluster \n")
plt.xlabel("-- 1 --")
plt.ylabel("-- 2 --")
plt.legend(title="Cluster")
plt.show()

"""‚úÖ Cluster 0 : Exploration / Mobilisation communautaire

Mots-cl√©s : pr√®s, amener, rencontrer, rejoindre, ouvrir
‚û°Ô∏è Interpr√©tation : Ce cluster semble li√© aux actions de terrain, au contact avec les communaut√©s, √† l‚Äôengagement ou mobilisation locale.

√âtiquette propos√©e : Mobilisation communautaire et terrain
‚úÖ Cluster 1 : Organisation / Logistique d‚Äô√©v√®nements

Mots-cl√©s : nouveau, for√™t, rencontre, chemise, grave
‚û°Ô∏è Interpr√©tation : M√©lange d‚Äô√©l√©ments logistiques et d‚Äôexp√©riences nouvelles ou impr√©vues, peut sugg√©rer des activit√©s sur le terrain ou en milieu rural, avec des al√©as logistiques.

√âtiquette propos√©e : D√©ploiement logistique et impr√©vus
‚úÖ Cluster 2 : R√©actions personnelles / Critiques ou doutes

Mots-cl√©s : inutile, conscience, r√©ponse, battre
‚û°Ô∏è Interpr√©tation : Feedbacks exprimant du doute, un sentiment d‚Äôinutilit√© ou de conflit, peut-√™tre li√©s √† une insatisfaction ou incompr√©hension.

√âtiquette propos√©e : Retours critiques ou insatisfaction
‚úÖ Cluster 3 : Sentiments / Ressenti √©motionnel

Mots-cl√©s : r√™ve, fatigue, naissance, inqui√©tude
‚û°Ô∏è Interpr√©tation : Retour √† dimension plus subjective, √©motionnelle, li√©e √† des sentiments profonds ou √† un effort intense, voire √©puisement.

√âtiquette propos√©e : Fatigue et √©motions personnelles
‚úÖ Cluster 4 : Perception positive / Appr√©ciation

Mots-cl√©s : plaisir, id√©e, impression, regarder, choisir
‚û°Ô∏è Interpr√©tation : Feedbacks plut√¥t positifs, avec des mots valorisant l‚Äôexp√©rience, l‚Äôint√©r√™t ou la clart√© des actions men√©es.

√âtiquette propos√©e : Perception positive et satisfaction
"""

