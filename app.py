import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import nltk
import string
import re
import json
from wordcloud import WordCloud
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.manifold import TSNE
from nltk.corpus import stopwords
from textblob import TextBlob
from sklearn.linear_model import LinearRegression
from openai import OpenAI

nltk.download('punkt')
nltk.download('stopwords')
stop_words = set(stopwords.words('french'))
# Initialiser le client avec la cl√©
client = OpenAI(api_key=st.secrets["openai"]["api_key"])

st.set_page_config(page_title="Analyse Feedbacks + Clustering IA", layout="wide")
st.title("üß† Analyse Automatis√©e de Feedbacks avec Th√®mes IA")

uploaded_file = st.file_uploader("üì§ Importez votre fichier CSV `suivi_activites.csv`", type=["csv"])

if uploaded_file:
    df = pd.read_csv(uploaded_file)

    st.success("‚úÖ Fichier charg√© avec succ√®s.")
    st.dataframe(df.head())

    def clean_text(text):
        if pd.isnull(text):
            return ""
        text = text.lower()
        text = text.translate(str.maketrans('', '', string.punctuation))
        text = re.sub(r'\d+', '', text)
        text = ' '.join([mot for mot in text.split() if mot not in stop_words])
        return text


    # Sentiment
    def compute_sentiment(text):
        return TextBlob(text).sentiment.polarity


    def classify_sentiment(score):
        if score > 0.1:
            return 'positif'
        elif score < -0.1:
            return 'n√©gatif'
        else:
            return 'neutre'
            
    def classer_sentiment(score):
        if score > 0.1:
            return 'POS'
        elif score < -0.1:
            return 'NEG'
        else:
            return 'NEU' 
        
    # LLM to generate theme labels
    def generate_theme_from_feedbacks(feedbacks):
        joined = "\n".join([f"- {f}" for f in feedbacks])
        prompt = (
            f"Voici des retours d‚Äôutilisateurs :\n{joined}\n\n"
            f"En tant que Data Scientist Quel est le th√®me commun √† ces retours qu'on peut degager ? "
            f"R√©ponds juste par un nom de th√®me clair, humainement compr√©hensible (4 mots max)."
        )
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        return response.choices[0].message.content.strip()
       
    
    # Checking matching between csv and json
    def valider_correspondance_geojson(df, geojson, csv_col='r√©gion', geojson_prop='region'):
        # Extraire les noms uniques du CSV
        regions_csv = set(df[csv_col].dropna().unique())
    
        # Extraire les noms du GeoJSON
        regions_geojson = set([f["properties"].get(geojson_prop, "").strip() for f in geojson["features"]])
    
        # Trouver les correspondances manquantes
        dans_csv_pas_geojson = regions_csv - regions_geojson
        dans_geojson_pas_csv = regions_geojson - regions_csv
    
        st.subheader("üîç Validation des noms de r√©gions")
        st.markdown(f"**‚úîÔ∏è Noms communs** : {regions_csv & regions_geojson}")
    
        if dans_csv_pas_geojson:
            st.error(f"‚ùå Ces r√©gions sont dans le CSV mais pas dans le GeoJSON : {dans_csv_pas_geojson}")
        if dans_geojson_pas_csv:
            st.warning(f"‚ö†Ô∏è Ces r√©gions sont dans le GeoJSON mais absentes du CSV : {dans_geojson_pas_csv}")
    
        if not dans_csv_pas_geojson and not dans_geojson_pas_csv:
            st.success("‚úÖ Toutes les r√©gions correspondent parfaitement.")
        
    # Conversion des donn√©es de la colonne Date en type date
    df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d', errors='coerce')

    ### ANALYSE EXPLORATOIRE DE BASE (EDA)
    
    df['Feedback_clean'] = df['feedback'].apply(clean_text)
    df['sentiment'] = df['Feedback_clean'].apply(compute_sentiment)
    df['sentiment_cat'] = df['sentiment'].apply(classify_sentiment)
    
    st.subheader("üìä Indicateurs de suivi d'activit√©s")
    # 1. Nombre total d'activit√©s
    st.metric("üìå Nombre total d‚Äôactivit√©s", len(df))
    
    # 2. Nombre d‚Äôactivit√©s par jour
    activites_par_jour = df.groupby('date').size()
    fig1, ax1 = plt.subplots(figsize=(10, 4))
    sns.lineplot(data=activites_par_jour, ax=ax1)
    ax1.set_title("üìÖ √âvolution du nombre d‚Äôactivit√©s par jour")
    ax1.set_xlabel("Date")
    ax1.set_ylabel("Nombre d‚Äôactivit√©s")
    st.pyplot(fig1)
    
    # 3. Activit√©s par r√©gion
    activites_par_region = df['r√©gion'].value_counts()
    fig2, ax2 = plt.subplots()
    sns.barplot(x=activites_par_region.values, y=activites_par_region.index, palette='Blues_r', ax=ax2)
    ax2.set_title("üìç Nombre total d‚Äôactivit√©s par r√©gion")
    st.pyplot(fig2)
    
    # 4. Activit√©s par localisation
    activites_par_localisation = df['localisation'].value_counts()
    fig3, ax3 = plt.subplots()
    sns.barplot(x=activites_par_localisation.values, y=activites_par_localisation.index, palette='Greens_r', ax=ax3)
    ax3.set_title("üìç Nombre total d‚Äôactivit√©s par localisation")
    st.pyplot(fig3)
    
    # 5. √âvolution par jour et r√©gion
    st.subheader("üìà Activit√©s par jour et par r√©gion")
    df_region = df.dropna(subset=['date', 'r√©gion'])
    activites_jour_region = df_region.groupby(['date', 'r√©gion']).size().reset_index(name='count')
    fig4, ax4 = plt.subplots(figsize=(12, 5))
    sns.lineplot(data=activites_jour_region, x='date', y='count', hue='r√©gion', ax=ax4)
    ax4.set_title("üìà Activit√©s par jour et r√©gion")
    ax4.set_xlabel("Date")
    ax4.set_ylabel("Nombre d‚Äôactivit√©s")
    st.pyplot(fig4)
    
    # 6. √âvolution par jour et type d‚Äôactivit√©s
    st.subheader("üìà Activit√©s par jour et par type d‚Äôactivit√©")
    df_type = df.dropna(subset=['date', 'type_activite'])
    activites_jour_type = df_type.groupby(['date', 'type_activite']).size().reset_index(name='count')
    fig5, ax5 = plt.subplots(figsize=(12, 5))
    sns.lineplot(data=activites_jour_type, x='date', y='count', hue='type_activite', ax=ax5)
    ax5.set_title("üìà Activit√©s par jour et type d‚Äôactivit√©")
    ax5.set_xlabel("Date")
    ax5.set_ylabel("Nombre d‚Äôactivit√©s")
    st.pyplot(fig5)
    
    
    st.subheader("üó∫Ô∏è Cartographies des sentiments")

    # Assurer que les donn√©es sont au bon format
    df['sentiment'] = pd.to_numeric(df['sentiment'], errors='coerce')
    
    # 1. Sentiment par localisation
    sentiment_loc = df.groupby('localisation')['sentiment'].mean().reset_index().dropna()
    fig1, ax1 = plt.subplots(figsize=(10, 4))
    sns.barplot(data=sentiment_loc, x='sentiment', y='localisation', palette='coolwarm', ax=ax1)
    ax1.set_title("üí¨ Sentiment moyen par localisation")
    ax1.set_xlabel("Score de sentiment")
    ax1.set_ylabel("Localisation")
    st.pyplot(fig1)
    
    # 2. Sentiment par r√©gion
    sentiment_reg = df.groupby('r√©gion')['sentiment'].mean().reset_index().dropna()
    fig2, ax2 = plt.subplots(figsize=(10, 4))
    sns.barplot(data=sentiment_reg, x='sentiment', y='r√©gion', palette='coolwarm', ax=ax2)
    ax2.set_title("üí¨ Sentiment moyen par r√©gion")
    ax2.set_xlabel("Score de sentiment")
    ax2.set_ylabel("R√©gion")
    st.pyplot(fig2)
    
    # 3. Sentiment par type d‚Äôactivit√©
    sentiment_type = df.groupby('type_activite')['sentiment'].mean().reset_index().dropna()
    fig3, ax3 = plt.subplots(figsize=(10, 4))
    sns.barplot(data=sentiment_type, x='sentiment', y='type_activite', palette='coolwarm', ax=ax3)
    ax3.set_title("üí¨ Sentiment moyen par type d‚Äôactivit√©")
    ax3.set_xlabel("Score de sentiment")
    ax3.set_ylabel("Type d‚Äôactivit√©")
    st.pyplot(fig3)
        
    # Graphique des sentiments par type d'activit√©
    plt.figure(figsize=(10,6))
    sns.countplot(data=df, x='type_activite', hue='sentiment_cat')
    plt.title("Sentiments par Type d'Activit√© \n")
    plt.xticks(rotation=45)
    #plt.show()
    st.pyplot(plt)

    # Moyenne de sentiment par localisation
    sentiment_localisation = df.groupby('localisation')['sentiment'].mean().sort_values()
    plt.figure(figsize=(8,5))
    sentiment_localisation.plot(kind='bar', color='skyblue')
    plt.title("Moyenne du sentiment par localisation \n")
    plt.ylabel("Score moyen de sentiment \n")
    #plt.show()
    st.pyplot(plt)

    # Croisement nombre participants vs sentiment (boxplot)
    plt.figure(figsize=(8,5))
    sns.boxplot(data=df, x='sentiment_cat', y='nombre_participants')
    plt.title("R√©partition des participants par sentiment \n")
    plt.show()
    st.pyplot(plt)

    # Wordcloud
    st.subheader("‚òÅÔ∏è Nuage de mots")
    wordcloud = WordCloud(width=1000, height=400, background_color='white').generate(' '.join(df['Feedback_clean']))
    plt.figure(figsize=(12, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis("off")
    st.pyplot(plt)
    
    # Nettoyage des feedbacks
    df = df.dropna(subset=['feedback'])  # Retirer les lignes sans feedback
    feedbacks = df['feedback'].astype(str).tolist()
    
    df['sentiment_label'] = df['sentiment'].apply(classer_sentiment)

    # Cr√©er une copie filtr√©e pour analyse
    df_filtered = df[df['sentiment_label'].isin(['POS', 'NEG'])].copy()

    # Cr√©er colonne mois-ann√©e
    df_filtered['mois_annee'] = df_filtered['date'].dt.to_period('M').astype(str)

    # Agr√©gation des feedbacks par mois et sentiment
    sentiment_par_mois = df_filtered.groupby(['mois_annee', 'sentiment_label']).size().unstack(fill_value=0)

    # Convertir l'index en entier pour les r√©gressions
    mois_index = np.arange(len(sentiment_par_mois)).reshape(-1, 1)

    sentiment_par_mois = sentiment_par_mois.astype(int)
    
    # Tracer le graphique avec lignes de tendance
    plt.figure(figsize=(12, 6))

    sentiment_par_mois.plot(
        kind='bar',
        color={'POS': '#66bb6a', 'NEG': '#ef5350'},
        edgecolor='black',
        width=0.75,
        ax=plt.gca()
    )
    # Ajout des courbes de tendance
    for sentiment in ['POS', 'NEG']:
        y = sentiment_par_mois[sentiment].values
        model = LinearRegression().fit(mois_index, y)
        trend = model.predict(mois_index)
        plt.plot(sentiment_par_mois.index, trend, linestyle='--', linewidth=2, label=f"Tendance {sentiment}")

    # Finalisation
    plt.title("√âvolution des sentiments par mois avec tendance \n")
    plt.xlabel("Mois-Ann√©e")
    plt.ylabel("Nombre de feedbacks")
    plt.xticks(rotation=45)
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    plt.legend(title="L√©gende")
    plt.tight_layout()
    plt.show()
    st.pyplot(plt)

    # === G√©n√©ration d'un commentaire automatique ===
    last = sentiment_par_mois.iloc[-1]
    first = sentiment_par_mois.iloc[0]

    evolution_pos = last['POS'] - first['POS']
    evolution_neg = last['NEG'] - first['NEG']

    commentaire = "üîé **Analyse automatique :**\n"

    if evolution_pos > 0:
        commentaire += f"- Les feedbacks **positifs ont augment√©** de {evolution_pos} entre {sentiment_par_mois.index[0]} et {sentiment_par_mois.index[-1]}.\n"
    elif evolution_pos < 0:
        commentaire += f"- Les feedbacks **positifs ont diminu√©** de {-evolution_pos} sur la m√™me p√©riode.\n"
    else:
        commentaire += "- Les feedbacks **positifs sont rest√©s stables**.\n"

    if evolution_neg > 0:
        commentaire += f"- Les feedbacks **n√©gatifs ont augment√©** de {evolution_neg}.\n"
    elif evolution_neg < 0:
        commentaire += f"- Les feedbacks **n√©gatifs ont diminu√©** de {-evolution_neg}.\n"
    else:
        commentaire += "- Les feedbacks **n√©gatifs sont rest√©s stables**.\n"

    st.markdown(commentaire)

    # TF-IDF + Clustering
    st.subheader("üìå Clustering th√©matique + renommage automatique avec IA")
    vectorizer = TfidfVectorizer(max_features=500, max_df=0.8, min_df=5)
    X = vectorizer.fit_transform(df['Feedback_clean'])

    n_clusters = 5
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    df['Cluster'] = kmeans.fit_predict(X)

    # G√©n√©ration des labels par LLM
    cluster_labels_llm = {}
    for i in range(n_clusters):
         feedbacks = df[df['Cluster'] == i]['feedback'].dropna().sample(min(10, len(df[df['Cluster'] == i]))).tolist()
         try:
             label = generate_theme_from_feedbacks(feedbacks)
         except Exception as e:
             label = f"Th√®me {i}"
             st.warning(f"Erreur dans le cluster {i} : {e}")
         cluster_labels_llm[i] = label
         st.markdown(f"**Cluster {i} ‚ûú {label}**")
         
         df['Cluster_Label'] = df['Cluster'].map(cluster_labels_llm)

    # t-SNE
    tsne = TSNE(n_components=2, random_state=42)
    X_embedded = tsne.fit_transform(X.toarray())
    df['Dim1'] = X_embedded[:, 0]
    df['Dim2'] = X_embedded[:, 1]

    fig = px.scatter(
        df, x='Dim1', y='Dim2',
        color='Cluster_Label',
        hover_data=['feedback', 'type_activite', 'r√©gion'],
        title="üìç Visualisation t-SNE avec th√®mes IA"
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # Affichage de la carte du Togo
    sentiment_par_region = df.groupby('r√©gion')['sentiment'].mean().reset_index()
    # Charger le fichier GeoJSON
    with open("togo_Regions_level_1.geojson", "r", encoding="utf-8") as f:
        togo_geo = json.load(f)
    
    valider_correspondance_geojson(df, togo_geo, csv_col='r√©gion', geojson_prop='region')
    
    # Sentiment par r√©gion (en s'assurant que les noms correspondent au GeoJSON)
    sentiment_region = df.groupby('r√©gion')['sentiment'].mean().reset_index()
    sentiment_region.columns = ['r√©gion', 'sentiment']

    # Carte choropl√®the
    fig = px.choropleth(
        sentiment_region,
        geojson=togo_geo,
        featureidkey="properties.r√©gion",  # doit correspondre au champ dans GeoJSON
        locations='r√©gion',
        color='sentiment',
        color_continuous_scale="RdYlGn",
        range_color=(-0.5, 0.5),
        labels={'sentiment': 'Score de sentiment'},
        title="üí¨ Sentiment moyen par r√©gion du Togo"
    )
    
    fig.update_geos(fitbounds="locations", visible=True)
    st.plotly_chart(fig, use_container_width=True)

    # Affichage enrichi
    st.subheader("üìÑ Donn√©es enrichies")
    st.dataframe(df[['id_activite', 'date', 'type_activite', 'r√©gion', 'feedback', 'Cluster_Label', 'sentiment_cat']])

else:
    st.info("Veuillez importer un fichier CSV pour commencer.")
